样本->变换、数字化（特征）->预处理（第七章）->特征选择（过滤不必要、影响小的特征）->模型选择（样本可视化后观测大概规律选择模型）->训练（k折交叉验证避免过拟合）->存储及应用（回归，分类）->结果可视化（通过B/S或C/S图表）

因为训练的时间、人力和物质成本导致模型很贵，训练时间可能达到日、月

回归分析，统计分类

算法原理
算法应用
算法优缺点评估

评价指标：
混淆矩阵
TP FN
FP TN
pre(精准率) = TP/(TP+FP)
Acc(准确率) = (TP+TN) / (所有)
** R(召回率、查全率) = TP/(TP+FN)

ROC曲线 (FPR, TPR)
FPR:阴判成阳 FN/(TN+FP)
TPR：阳正确判断为阳
AUC(area under curve ) = (1 + TPR - FPR) / 2
随机猜测AUC=0.5
...等等...

实际中处理的是非确定性关系，两个变量在公关上存在关系，但未经确找到可用函数关系表达，但是尽量向确定性关系（有准确的函数关系）靠拢
y^=a+bx 为非确定性关系
y=a+bx 未确定性关系

训练实际是找a和b的参数
最优解通过最小二乘法保证平方和最小（每个点到线上的垂直[纵向]距离最短）即损失函数（Y-Y^为残差）loss = min(∑(Y-Y^)²=∑[Yi-(a+bxi)]²) 平均的损失函数1/N*loss 实际不可能为0，为0即在线上
1/N不影响其趋势
xi yi 已知，极值存在于一阶偏导数=0的点，（同时对a,b求偏导，且同时为0的点）


1-多元线性回归
Y不仅仅取决于一个X
而是Y=b0+b1x1+b2x2+...+e  e为随机残差（噪声）
还是分别对所有系数求偏导同时等于0的点

2-KNN——找最好的K，几个邻居效果最好
找出前k个距离最短

相似度体现在某些维度上的距离
求距离几种方法：
1.欧氏距离:((x1-x2)^2 + (y1-y2)^2)^1/2 ，但是可能弱化某些特征的权重，差很小但是特征很明显，所以可在每项前面除以权值标准化特征，标准化欧氏距离
2.归一化，放在[0,1]中
3.曼哈顿距离
--------
|-|-|-|-|
|网格-  |
--------
只能走横向或纵向，地图距离使用曼哈顿，因为基本不可能走直线

马氏距离使用协方差矩阵计算
人脸128个特征可视化分析出那些特征几乎无差别并剔除

劣势：样本不平衡，样本分布不均匀
》》》解决：1.动态权值，越近的距离权值越高
     样本增多计算量大，与每一个样本一一计算距离
》》》解决：1.分组快速搜索近邻法，找每一组的中心（质心、重心）[但是，边界上样本点存在感太模糊]


-----------
SVM
wx + b = 0
w -> 法向量 Ax+By+Cz=0一个经过原点的平面，在高中时期关注的是平面之间的关系，并没有确定一个平面，已知一个法向量，为了确定平面在空间的位置还需要一个平面偏移量
而确定一个超平面可通过两个超平面确定一个中间的平面 wx+b=c和wx+b=-c,同时除以c,将w/c代还为w，原式wx+b=0除以c也没有变化,为了方便计算两个平面变成wx+b=±1